{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb3bda9b",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b556fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io.wavfile as wavfile\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "from scipy.fftpack import fft, ifft\n",
    "import cv2\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a34354",
   "metadata": {},
   "source": [
    "# Data preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "569c80b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining variables used for reading the data\n",
    "\n",
    "classes = [\"Alarm\", \"Blender\", \"Microwave\", \"Music\", \"Silence\", \"Vacuum\"]\n",
    "samples_per_class = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab650a80",
   "metadata": {},
   "source": [
    "## Reading in all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6e31d3d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Timmy\\AppData\\Local\\Temp\\ipykernel_12668\\824154626.py:7: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  fs,y=wavfile.read(path + f\"{i}.wav\")\n"
     ]
    }
   ],
   "source": [
    "# Data is stored in a two dimensional list with first dimension beeing the class and the second dimension the samples\n",
    "data = [[] for _ in range(len(classes))]\n",
    "\n",
    "for cls_number, cls_name in enumerate(classes):\n",
    "    path = f\"Data/{cls_name}/{cls_name}_\"\n",
    "    for i in range(samples_per_class):\n",
    "        fs,y=wavfile.read(path + f\"{i}.wav\")\n",
    "        data[cls_number].append([fs, y])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb7a527",
   "metadata": {},
   "source": [
    "## Removing all frequencies above 10 kHz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a1ca59",
   "metadata": {},
   "source": [
    "For preprocessing the data all frequencies above 10 kHz are removed. It is assumed that these higher frequencies are created by noise and therefore do not hold any information about the data. A comparison between the original data and the preprocessed showed that it still sounds the same and looks similar in the time domain, so it is assumed to be safe to remove these frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4b3ae94",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cls_number in range(len(data)):\n",
    "    for i in range(len(data[cls_number])):\n",
    "        audio_data = data[cls_number][i][1]\n",
    "        T = 1/data[cls_number][i][0]\n",
    "        N = len(audio_data)\n",
    "        max_val = 1.0/(2.0*T)\n",
    "        num_vals = N//2  \n",
    "\n",
    "        yf = fft(audio_data)\n",
    "\n",
    "        xf = np.linspace(0.0, max_val, num_vals)\n",
    "        \n",
    "        i_over_10kHz = np.argmax(xf > 10000)\n",
    "        yf[i_over_10kHz: len(yf) - i_over_10kHz] = 0.0\n",
    "        data[cls_number][i][1] = ifft(yf).real"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91001f88",
   "metadata": {},
   "source": [
    "## Windowing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d86235e",
   "metadata": {},
   "source": [
    "Chosen approach: Single window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d0a61e",
   "metadata": {},
   "source": [
    "### Single window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943b52d5",
   "metadata": {},
   "source": [
    "By reading in the data samples as a whole, a single window is already used. So therefore no further implementation is needed for the single window approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a6b8d6",
   "metadata": {},
   "source": [
    "### Multiple windows (running this cell decreases the testing accuracy of the SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17eea33",
   "metadata": {},
   "source": [
    "As shown by the window size performance comparison in the \"Data visualization\" segtion, the single window approach gives the best performance for the SVM. Random Forest has a testing accuracy of 100% with all tested window sizes. But because of the better accuracy for the SVM, the single window approach is chosen and this cell should not be executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab16303",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 10  # in seconds\n",
    "overlap = 0.5  # in per cent\n",
    "\n",
    "data_windowed = [[] for _ in range(len(data))]\n",
    "\n",
    "for cls_number in range(len(data)):\n",
    "    for i in range(len(data[cls_number])):\n",
    "        sample_rate = data[cls_number][i][0]\n",
    "        indexes_per_window = window_size * sample_rate\n",
    "        end_index = indexes_per_window\n",
    "        while end_index < len(data[cls_number][i][1]):\n",
    "            data_windowed[cls_number].append([sample_rate, data[cls_number][i][1][end_index - indexes_per_window:end_index]])\n",
    "            end_index += int((1 - overlap) * indexes_per_window)\n",
    "        \n",
    "data = data_windowed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb07c94a",
   "metadata": {},
   "source": [
    "## Creating spectrograms of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1748e54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "FFT_SIZE=1024\n",
    "data_spectrograms = [[] for _ in range(len(data))]\n",
    "for cls_number in range(len(data)):\n",
    "    for i in range(len(data[cls_number])):\n",
    "        f,t,pxx = signal.spectrogram(data[cls_number][i][1], nperseg=FFT_SIZE, fs=data[cls_number][i][0], noverlap=FFT_SIZE/2)\n",
    "        data_spectrograms[cls_number].append([f, t, pxx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236f2355",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06263605",
   "metadata": {},
   "source": [
    "## Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0eaa104",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_freq_bins=5\n",
    "num_time_bins=5\n",
    "\n",
    "data_spectrograms_binned = [[] for _ in range(len(data))]\n",
    "\n",
    "for cls_number in range(len(data_spectrograms)):\n",
    "    for i in range(len(data_spectrograms[cls_number])):\n",
    "        resized_pxx = cv2.resize(data_spectrograms[cls_number][i][2],(num_time_bins,num_freq_bins))\n",
    "        data_spectrograms_binned[cls_number].append([data_spectrograms[cls_number][i][0], data_spectrograms[cls_number][i][1], resized_pxx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003ea87f",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3f28dc",
   "metadata": {},
   "source": [
    "Chosen features:\n",
    "\n",
    "- All bins from the binned spectrogram (25 features)\n",
    "- Three frequencies with the highest magnitude (3 features)\n",
    "- Mean magnitude of the frequencies (1 feature)\n",
    "- Median magnitude of the frequencies (1 feature)\n",
    "- Variance of the magnitudes of the frequencies (1 feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bb4449a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frequency_features(cls_number: int, i: int) -> list:\n",
    "    audio_data = data[cls_number][i][1]\n",
    "    T = 1/data[cls_number][i][0]\n",
    "    N = len(audio_data)\n",
    "    max_val = 1.0/(2.0*T)\n",
    "    num_vals = N//2  \n",
    "\n",
    "    yf_all = fft(audio_data)\n",
    "    yf = 2.0/N * np.abs(yf_all[0:num_vals])\n",
    "\n",
    "    xf = np.linspace(0.0, max_val, num_vals)\n",
    "\n",
    "    sorted_frequencies = np.argsort(yf)\n",
    "    \n",
    "    return [xf[sorted_frequencies[-1]], xf[sorted_frequencies[-2]], xf[sorted_frequencies[-3]], np.mean(yf), np.median(yf), np.var(yf)]\n",
    "\n",
    "        \n",
    "data_features = [[] for _ in range(len(data))]\n",
    "\n",
    "for cls_number in range(len(data_spectrograms_binned)):\n",
    "    for i in range(len(data_spectrograms_binned[cls_number])):\n",
    "        features = data_spectrograms_binned[cls_number][i][2].reshape((-1,)).tolist()\n",
    "        features.extend(extract_frequency_features(cls_number, i))\n",
    "        data_features[cls_number].append(np.asarray(features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89208db1",
   "metadata": {},
   "source": [
    "## Creating labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "560b3e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "labels_list = []\n",
    "\n",
    "for cls_number in range(len(data_features)):\n",
    "    for i in range(len(data_features[cls_number])):\n",
    "        data_list.append(data_features[cls_number][i])\n",
    "        labels_list.append(cls_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a60d73",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64b1203",
   "metadata": {},
   "source": [
    "Neccesarry for the SVM to achieve 100% testing accuracy, for the Random Forest it does not matters if the data is normalized or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8daf90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "data_list = scaler.fit_transform(data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67282ff",
   "metadata": {},
   "source": [
    "## Create training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02acafe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(data_list, labels_list, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aabf018",
   "metadata": {},
   "source": [
    "# ML models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443a7525",
   "metadata": {},
   "source": [
    "Two machine learning algorithms have been tested for this assignment. Firstly a SVM with a linear kernel, which has a testing accuracy of 100%. Also Random Forest has been implemented and achieves a testing accuracy of 100% as well. In order for the SVM to achieve 100%, the data has to be normalized. For the Random Forest model it does not matter and it achieves 100% with and without normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44fd851",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2001ea30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Cross Validation Score from Training:\n",
      "1.0\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[7 0 0 0 0 0]\n",
      " [0 5 0 0 0 0]\n",
      " [0 0 7 0 0 0]\n",
      " [0 0 0 7 0 0]\n",
      " [0 0 0 0 5 0]\n",
      " [0 0 0 0 0 5]]\n",
      "\n",
      "\n",
      "Test Statistics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       1.00      1.00      1.00         5\n",
      "           2       1.00      1.00      1.00         7\n",
      "           3       1.00      1.00      1.00         7\n",
      "           4       1.00      1.00      1.00         5\n",
      "           5       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "\n",
      "\n",
      "Testing Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "clf.fit(xtrain, ytrain)\n",
    "cv_scores = cross_val_score(clf, xtrain, ytrain, cv=10)\n",
    "print('Average Cross Validation Score from Training:', cv_scores.mean(), sep='\\n', end='\\n\\n\\n')\n",
    "\n",
    "ypred = clf.predict(xtest)\n",
    "cm = confusion_matrix(ytest, ypred)\n",
    "cr = classification_report(ytest, ypred)\n",
    "\n",
    "print('Confusion Matrix:', cm, sep='\\n', end='\\n\\n\\n')\n",
    "print('Test Statistics:', cr, sep='\\n', end='\\n\\n\\n')\n",
    "\n",
    "print('Testing Accuracy:', accuracy_score(ytest, ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f453ecea",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81f386f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel=\"linear\")\n",
    "clf.fit(xtrain, ytrain)\n",
    "cv_scores = cross_val_score(clf, xtrain, ytrain, cv=10)\n",
    "print('Average Cross Validation Score from Training:', cv_scores.mean(), sep='\\n', end='\\n\\n\\n')\n",
    "\n",
    "ypred = clf.predict(xtest)\n",
    "cm = confusion_matrix(ytest, ypred)\n",
    "cr = classification_report(ytest, ypred)\n",
    "\n",
    "print('Confusion Matrix:', cm, sep='\\n', end='\\n\\n\\n')\n",
    "print('Test Statistics:', cr, sep='\\n', end='\\n\\n\\n')\n",
    "\n",
    "print('Testing Accuracy:', accuracy_score(ytest, ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b78a861",
   "metadata": {},
   "source": [
    "# Live demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3112c5",
   "metadata": {},
   "source": [
    "Run all cells above except:\n",
    "\n",
    "- Multiple windows\n",
    "- Normalization\n",
    "- SVM\n",
    "\n",
    "And then run the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c20dec5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start classifying\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Music\n",
      "Microwave\n",
      "Music\n",
      "Microwave\n",
      "Music\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "Microwave\n",
      "classifying stopped\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "\n",
    "def fft_preparations(data_points: np.ndarray, sample_rate: int = 44100) -> np.ndarray:\n",
    "    T = 1/sample_rate\n",
    "    N = len(data_points)\n",
    "    max_val = 1.0/(2.0*T)\n",
    "    num_vals = N//2  \n",
    "\n",
    "    yf = fft(data_points)\n",
    "\n",
    "    xf = np.linspace(0.0, max_val, num_vals)\n",
    "\n",
    "    i_over_10kHz = np.argmax(xf > 10000)\n",
    "    yf[i_over_10kHz: len(yf) - i_over_10kHz] = 0.0\n",
    "    \n",
    "    yf_normalized = 2.0/N * np.abs(yf[0:num_vals])\n",
    "    sorted_frequencies = np.argsort(yf_normalized)\n",
    "    \n",
    "    return ifft(yf).real, [xf[sorted_frequencies[-1]], xf[sorted_frequencies[-2]], xf[sorted_frequencies[-3]], np.mean(yf_normalized), np.median(yf_normalized), np.var(yf_normalized)]\n",
    "\n",
    "def spectrograms_binned(data_points: np.ndarray, sample_rate: int = 44100) -> np.ndarray:\n",
    "    _,_,pxx = signal.spectrogram(data_points, nperseg=1024, fs=sample_rate, noverlap=512)\n",
    "    return cv2.resize(pxx,(5,5))\n",
    "\n",
    "def generate_features(data_points: np.ndarray, sample_rate: int = 44100) -> np.ndarray:\n",
    "    data_points_new, features_fft = fft_preparations(data_points, sample_rate)\n",
    "    features = spectrograms_binned(data_points_new, sample_rate).reshape((-1,)).tolist()\n",
    "    features.extend(features_fft)\n",
    "    return np.asarray([features])\n",
    "\n",
    "\n",
    "CHUNK=5192\n",
    "FORMAT=pyaudio.paInt16\n",
    "CHANNELS=1\n",
    "RATE=44100\n",
    "\n",
    "p=pyaudio.PyAudio()\n",
    "stream=p.open(format=FORMAT,channels=CHANNELS,rate=RATE,input=True,frames_per_buffer=CHUNK)\n",
    "print(\"start classifying\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        data_chunk=stream.read(CHUNK)\n",
    "        data_points = np.frombuffer(data_chunk, dtype=np.int16)\n",
    "        features = generate_features(data_points, RATE)\n",
    "        predicted_class = clf.predict(features)\n",
    "        print(classes[predicted_class[0]])\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "\n",
    "print(\"classifying stopped\")\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "p.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6cbfce",
   "metadata": {},
   "source": [
    "# Data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6867e9a0",
   "metadata": {},
   "source": [
    "Tipps for adressing the audio data in the data list:\n",
    "\n",
    "- First index defines class of data (see classes list at the top)\n",
    "- Second index is the number of the sample\n",
    "- Third index decides between sample rate and actual data (0 = sample rate; 1 = audio data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd8ec63",
   "metadata": {},
   "source": [
    "## Play audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da56a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "\n",
    "Audio(data=data[3][9][1], rate=data[3][9][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d505f0e0",
   "metadata": {},
   "source": [
    "## Plot audio in time domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a04797f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "\n",
    "plt.figure()\n",
    "librosa.display.waveshow(np.asarray(data[3][9][1], dtype=float), sr=data[3][9][0])\n",
    "plt.xlabel(\"Time (seconds)\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e759f1ce",
   "metadata": {},
   "source": [
    "## Plot audio in frequency domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161ba992",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fftpack import fft\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def fft_method(audio, sampling_rate):\n",
    "    T = 1/sampling_rate\n",
    "    N = len(audio)\n",
    "    max_val = 1.0/(2.0*T)\n",
    "    num_vals = N//2  \n",
    "    \n",
    "    yf_all = fft(audio)\n",
    "    \n",
    "    xf = np.linspace(0.0, max_val, num_vals)\n",
    "    yf = 2.0/N * np.abs(yf_all[0:num_vals])\n",
    "    \n",
    "    return xf, yf\n",
    "\n",
    "\n",
    "xf, yf = fft_method(data[3][9][1], data[3][9][0])\n",
    "\n",
    "plt.plot(xf, yf)\n",
    "plt.grid()\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.ylabel(\"Magnitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8cdc8b",
   "metadata": {},
   "source": [
    "## Plot spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd41f24",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "cmap=plt.cm.bone\n",
    "cmap.set_under(color='k', alpha=None)\n",
    "plt.pcolormesh(np.log10(data_spectrograms[3][9][2]),cmap=cmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf64d44",
   "metadata": {},
   "source": [
    "## Plot binned spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befb9344",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "cmap=plt.cm.bone\n",
    "cmap.set_under(color='k', alpha=None)\n",
    "plt.pcolormesh(np.log10(data_spectrograms_binned[3][9][2]),cmap=cmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f90fa6",
   "metadata": {},
   "source": [
    "## Plot binned spectrograms of all classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56408cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "cmap=plt.cm.bone\n",
    "cmap.set_under(color='k', alpha=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44904642",
   "metadata": {},
   "source": [
    "### Alarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bfa822",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(np.log10(data_spectrograms_binned[0][0][2]),cmap=cmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6f3799",
   "metadata": {},
   "source": [
    "### Blender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925ece3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.pcolormesh(np.log10(data_spectrograms_binned[1][0][2]),cmap=cmap)\n",
    "print(data_spectrograms_binned[1][0][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaf5f59",
   "metadata": {},
   "source": [
    "### Microwave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f8e9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(np.log10(data_spectrograms_binned[2][0][2]),cmap=cmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced63ee0",
   "metadata": {},
   "source": [
    "### Music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c247a0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(np.log10(data_spectrograms_binned[3][0][2]),cmap=cmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786bc0ed",
   "metadata": {},
   "source": [
    "### Silence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a24ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(np.log10(data_spectrograms_binned[4][0][2]),cmap=cmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d087616",
   "metadata": {},
   "source": [
    "### Vacuum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859499c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(np.log10(data_spectrograms_binned[5][0][2]),cmap=cmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0a844a",
   "metadata": {},
   "source": [
    "## Window size comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad275fba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Overlap of 50%\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "window_sizes = [5, 10, 15, 20, 25, 30, 'Single window']\n",
    "results_svm = [98.6, 98.6, 97.9, 97.2, 95.8, 91.7, 100.0]\n",
    "results_rf = [100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0]\n",
    "\n",
    "plt.plot(window_sizes, results_svm, \"x\", label=\"SVM\")\n",
    "plt.plot(window_sizes, results_rf, \"x\", label=\"Random Forest\")\n",
    "plt.xlabel(\"Window size in seconds\")\n",
    "plt.ylabel(\"Testing accuracy in per cent\")\n",
    "plt.title(\"Comparison of different window sizes\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f4ec61",
   "metadata": {},
   "source": [
    "## Comparison feature combinations and window sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27cb725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_labels = ['Multiple windows with spectrogram', 'Multiple windows with binned spectrogram',\n",
    "           'Multiple windows with spectrogram and other features',\n",
    "            'Multiple windows with binned spectrogram and other features',\n",
    "           'Single window with spectrogram', 'Single window with binned spectrogram',\n",
    "           'Single window with spectrogram and other features',\n",
    "            'Single window with binned spectrogram and other features']\n",
    "x_values = np.arange(8) + 1\n",
    "\n",
    "svm_results = [100.0, 66.3, 100.0, 99.4, 100.0, 72.2, 100.0, 100.0]\n",
    "rf_results = [100.0, 97.8, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0]\n",
    "\n",
    "plt.plot(x_values, svm_results, \"x\", label=\"SVM\")\n",
    "plt.plot(x_values, rf_results, \"x\", label=\"Random Forest\")\n",
    "plt.xlabel(\"Number of the tested configuration\")\n",
    "plt.ylabel(\"Testing accuracy in per cent\")\n",
    "plt.title(\"Comparison of different configurations\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537e78be",
   "metadata": {},
   "source": [
    "Explanation of the meanings of the configuration number:\n",
    "\n",
    "- 1: Multiple windows with only the spectrogram data as features\n",
    "- 2: Multiple windows with only the binned spectrogram as features\n",
    "- 3: Multiple windows with the spectrogram data and the other features\n",
    "- 4: Multiple windows with the binned spectrogram data and the other features\n",
    "- 5: Single window with only the spectrogram data as features\n",
    "- 6: Single window with only the binned spectrogram as features\n",
    "- 7: Single window with the spectrogram data and the other features\n",
    "- 8: Single window with the binned spectrogram data and the other features\n",
    "\n",
    "For all multiple window configurations a window size of 10 seconds and 50% overlap have been chosen"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
